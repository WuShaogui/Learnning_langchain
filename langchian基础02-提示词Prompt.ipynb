{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示词指的是输入到llm的文本，一个准确的提问会让llm的回答更加准确，提示词不仅改变提问内容，还涉及逻辑思维、迭代优化问题，所以有学科（岗位）叫提示词开发工程师\n",
    "\n",
    "langchain抽象了提示词组件，方便定义、修改提示词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AIMessagePromptTemplate', 'BaseChatPromptTemplate', 'BasePromptTemplate', 'ChatMessagePromptTemplate', 'ChatPromptTemplate', 'FewShotChatMessagePromptTemplate', 'FewShotPromptTemplate', 'FewShotPromptWithTemplates', 'HumanMessagePromptTemplate', 'PipelinePromptTemplate', 'Prompt', 'PromptTemplate', 'StringPromptTemplate', 'SystemMessagePromptTemplate', 'load_prompt', 'prompt']\n"
     ]
    }
   ],
   "source": [
    "from langchain import prompts\n",
    "atts=list(filter(lambda att:att.lower().find('prompt')>=0,dir(prompts)))\n",
    "print(atts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过查看这个组件的模块，可以看到其中主要有3个基类`BasePromptTemplate`，`BaseChatPromptTemplate`、`PromptValue`，我们分别学习其中代表性的`PromptTemplate`、`ChatPromptTemplate`\n",
    "\n",
    "```mermaid\n",
    "classDiagram\n",
    "    class BasePromptTemplate\n",
    "    class PipelinePromptTemplate\n",
    "    class StringPromptTemplate\n",
    "    class BaseChatPromptTemplate\n",
    "    class PromptTemplate\n",
    "    class FewShotPromptTemplate\n",
    "    class FewShotPromptWithTemplates\n",
    "    class AutoGPTPrompt\n",
    "    class ChatPromptTemplate\n",
    "    class AgentScratchPadChatPromptTemplate\n",
    "    class BaseMessagePromptTemplate\n",
    "    class MessagesPlaceholder\n",
    "    class BaseStringMessagePromptTemplate\n",
    "    class HumanMessagePromptTemplate\n",
    "    class AIMessagePromptTemplate\n",
    "    class SystemMessagePromptTemplate\n",
    "\n",
    "    PromptValue<|-- StringPromptValue\n",
    "    PromptValue<|-- ChatPromptValue\n",
    "                    \n",
    "    BasePromptTemplate <|-- PipelinePromptTemplate\n",
    "    BasePromptTemplate <|-- StringPromptTemplate\n",
    "    BasePromptTemplate <|-- BaseChatPromptTemplate\n",
    "\n",
    "    StringPromptTemplate <|-- PromptTemplate\n",
    "    StringPromptTemplate <|-- FewShotPromptTemplate\n",
    "    StringPromptTemplate <|-- FewShotPromptWithTemplates\n",
    "    BaseChatPromptTemplate <|-- AutoGPTPrompt\n",
    "    BaseChatPromptTemplate <|-- ChatPromptTemplate\n",
    "    ChatPromptTemplate <|-- AgentScratchPadChatPromptTemplate\n",
    "    BaseMessagePromptTemplate <|-- MessagesPlaceholder\n",
    "    BaseMessagePromptTemplate <|--                               BaseStringMessagePromptTemplate\n",
    "    BaseStringMessagePromptTemplate <|-- ChatMessagePromptTemplate\n",
    "    ChatMessagePromptTemplate <|-- HumanMessagePromptTemplate\n",
    "    ChatMessagePromptTemplate <|-- AIMessagePromptTemplate\n",
    "    ChatMessagePromptTemplate <|-- SystemMessagePromptTemplate                                               \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字符串提示模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='你是城市广州的导游，负责带国外游客去白云山游玩')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template=\"\"\"你是城市{city}的导游，负责带{place}游客去白云山游玩\"\"\"\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "prompt=prompt_template.invoke({'city':\"广州\",'place':\"国外\"})\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，提示模板接受一个字典作为输入，其中每个键表示提示模板中要填充的变量,ChatPromptTemplate 类似 ptyhon 的 string.format()，先声明变量位置，然后往里面填值，基于以上内容直接输入llm，可以得到llm答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非常高兴能为您服务！作为您的导游，我将带领您探索广州市著名的白云山。现在，请允许我先向您介绍一下白云山的基本情况和一些游览小贴士。\n",
      "\n",
      "### 白云山概况\n",
      "\n",
      "- **地理位置**：位于广州市中心偏北位置，东临珠江，西连广州大学城。\n",
      "- **自然风光**：作为广州市的“绿肺”，白云山拥有丰富的植被，四季皆有不同的景色。春天赏花、夏天避暑、秋天观叶、冬天雪景（虽较少见）都各有特色。\n",
      "- **人文景观**：除了自然风光外，山上还分布着许多历史遗迹和文化景点。\n",
      "\n",
      "### 游览路线与行程安排\n",
      "\n",
      "我们今天将沿着主要的登山步道进行游览。全程大约需要3-4小时左右，具体时间取决于您的体力情况和个人兴趣。\n",
      "\n",
      "1. **入口进入**\n",
      "   - 从白云山南门进入（建议选择这一入口，因为这里人流相对较少且风景较佳）。\n",
      "2. **主干道路线**\n",
      "   - 走过主要的登山步道，一路上可以欣赏到不同种类的树木和花卉。\n",
      "3. **重要景点参观**：\n",
      "   - 沿途会经过摩星岭、鸣春谷等著名景点。您可以在这些地方稍作停留拍照或休息。\n",
      "4. **返回**\n",
      "   - 根据您的体力情况和时间安排，可以选择直接下山或者选择乘坐缆车快速返回。\n",
      "\n",
      "### 注意事项\n",
      "\n",
      "- 请穿着舒适的鞋子并带上足够的水份补给。\n",
      "- 夏季记得涂抹防晒霜，并随身携带太阳镜等防晒用品。\n",
      "- 携带一些简单的零食，在休息时享用。\n",
      "- 尊重自然，不要乱丢垃圾或破坏植被。\n",
      "\n",
      "如果您有任何特殊需求或者想要探索特定的地方，请随时告知我。希望这次游览能让您更好地了解广州这座美丽的城市！\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "# 初始化Ollama LLM，注意需要后台开启ollama服务\n",
    "model_name = \"qwen2.5:latest\"\n",
    "model  = OllamaLLM(model=model_name,base_url='http://localhost:11434')\n",
    "response=model.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聊天提示词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上只是向llm发送一次提问，如果要向llm发送“一段对话”，可以使用`ChatPromptTemplate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='把由三个反引号分隔的文本翻译成一种普通话风格。文本: ```Hello, Guangzhou!```\\n', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# 首先，构造一个提示模版字符串：`template_string`\n",
    "template_string = \"\"\"把由三个反引号分隔的文本\\\n",
    "翻译成一种{style}风格。\\\n",
    "文本: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "chat_prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "chat_prompt=chat_prompt_template.invoke({'style':\"普通话\",'text':\"Hello, Guangzhou!\"})\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```你好，广州！```', additional_kwargs={}, response_metadata={'model': 'qwen2.5:latest', 'created_at': '2024-12-30T05:54:33.4289242Z', 'done': True, 'done_reason': 'stop', 'total_duration': 607320800, 'load_duration': 58754400, 'prompt_eval_count': 55, 'prompt_eval_duration': 109000000, 'eval_count': 7, 'eval_duration': 436000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-65f06d12-295a-4540-81f2-b267750fc470-0', usage_metadata={'input_tokens': 55, 'output_tokens': 7, 'total_tokens': 62})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "# 初始化Ollama LLM，注意需要后台开启ollama服务\n",
    "model_name = \"qwen2.5:latest\"\n",
    "chat_model  = ChatOllama(model=model_name,base_url='http://localhost:11434')\n",
    "\n",
    "response=chat_model.invoke(chat_prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，这里为了区分人类信息、机器信息，langchian抽象出Messege的概念，并以HumanMessage、AIMessage区分，当准备向llm传递一段对话时，可以进行以下操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我是来自阿里云的AI助手小广，专门为您提供关于广州的相关信息和问题解答。有什么关于广州的问题可以随时问我哦！', additional_kwargs={}, response_metadata={'model': 'qwen2.5:latest', 'created_at': '2024-12-30T05:38:50.4394312Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1093494400, 'load_duration': 39523600, 'prompt_eval_count': 64, 'prompt_eval_duration': 112000000, 'eval_count': 30, 'eval_duration': 939000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-59bc1e0b-8a99-4351-bd2d-ede51ba97337-0', usage_metadata={'input_tokens': 64, 'output_tokens': 30, 'total_tokens': 94})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "\n",
    "messages=[\n",
    "    HumanMessage(content=\"你叫小广，专门回答关于广州的问题\"),\n",
    "    AIMessage(content=\"好的，我叫小广，设计用于回答广州的问题\"),\n",
    "    HumanMessage(content=\"你是谁？\")\n",
    "]\n",
    "\n",
    "response=chat_model.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际上，langchian不仅有`AIMessage`,`HumanMessage`，还有以下Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AIMessage', 'AIMessageChunk', 'AnyMessage', 'BaseMessage', 'BaseMessageChunk', 'ChatMessage', 'ChatMessageChunk', 'FunctionMessage', 'FunctionMessageChunk', 'HumanMessage', 'HumanMessageChunk', 'MessageLikeRepresentation', 'RemoveMessage', 'SystemMessage', 'SystemMessageChunk', 'ToolMessage', 'ToolMessageChunk', '_message_from_dict', 'convert_to_messages', 'convert_to_openai_messages', 'filter_messages', 'merge_message_runs', 'message_chunk_to_message', 'message_to_dict', 'messages_from_dict', 'messages_to_dict', 'trim_messages']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core import messages\n",
    "atts=list(filter(lambda att:att.lower().find('message')>=0,dir(messages)))\n",
    "print(atts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段脚本展示了如何使用LangChain库中的提示词组件来构建和调用LLM（大型语言模型），具体包括**字符串提示模板、聊天提示模板以及消息对象**的使用。更复杂的使用包括：使用少样本提示选择器、绑定结构化输出解释器，这将在进阶内容上提出"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
