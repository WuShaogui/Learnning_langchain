{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs的直接输出是文本，没用结构性，导致LLMs后续的操作存在不确定性，无法构建后续应用。一个比较常见的例子是：从特定文本提取某些字段的数据保存到数据库中。\n",
    "\n",
    "以下我们问模型一个问题，比较没经过结构化、结构化后的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='好的，根据您提供的信息，张三是25岁的男性，身高为168厘米。请问您接下来需要了解或讨论关于张三的哪些方面呢？如果是用于构建一个更详细的人物背景，或者如果有其他相关问题，请告诉我。' additional_kwargs={} response_metadata={'model': 'qwen2.5:7b', 'created_at': '2024-10-11T07:30:45.486678904Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 760356188, 'load_duration': 27512029, 'prompt_eval_count': 41, 'prompt_eval_duration': 49551000, 'eval_count': 54, 'eval_duration': 538008000} id='run-c8c1e4d9-c860-4cf6-bc60-7a7d934156a1-0' usage_metadata={'input_tokens': 41, 'output_tokens': 54, 'total_tokens': 95}\n",
      "content='李四是位28岁的男士，身高172厘米。如果您需要更多关于他的信息，请提供更多细节或者具体问题。例如，您是否想知道他的体重、职业或者其他相关信息？' additional_kwargs={} response_metadata={'model': 'qwen2.5:7b', 'created_at': '2024-10-11T07:30:46.067307087Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 577732371, 'load_duration': 22191140, 'prompt_eval_count': 41, 'prompt_eval_duration': 27672000, 'eval_count': 40, 'eval_duration': 387834000} id='run-22f750fd-ea2a-4603-a998-aa76cd408dc3-0' usage_metadata={'input_tokens': 41, 'output_tokens': 40, 'total_tokens': 81}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "# 初始化Ollama LLM，注意需要后台开启ollama服务\n",
    "model_name = \"qwen2.5:7b\"\n",
    "llm  = ChatOllama(model=model_name)\n",
    "\n",
    "response=llm.invoke(\"张三25岁，并且有168厘米\")\n",
    "print(response)\n",
    "\n",
    "response=llm.invoke(\"李四28岁，并且有172厘米\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，直接问模型，没用定义结构化输出，模型输出内容不可控，下面对输出进行结构化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='张三', height_in_meters=1.68)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    height_in_meters: float = Field(..., description=\"The height of the person expressed in meters.\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(Person) # 可以绑定结构化输出\n",
    "structured_llm.invoke(\"张三25岁，并且有168厘米\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，模型输出形成有固定结构的内容！\n",
    "实际上langchain提供2种方式去设置LLMs的“结构化”输出，以下内容探索langchain结构化输出的原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过with_structured_output函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='张三', height_in_meters=1.68)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "model_name = \"qwen2.5:7b\"\n",
    "llm = ChatOllama(model=model_name)\n",
    "\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    height_in_meters: float = Field(..., description=\"The height of the person expressed in meters.\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(Person) # 可以绑定结构化输出\n",
    "structured_llm.invoke(\"张三25岁，并且有168厘米\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上例子演示使用Pydantic class构建格式化的prompt,实际上with_structured_output接受以下输入：\n",
    "\n",
    "- an OpenAI function/tool schema,\n",
    "- a JSON Schema,\n",
    "- a TypedDict class (support added in 0.1.20),\n",
    "- or a Pydantic class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义结构化输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，并不是所有模型都实现了with_structured_output函数，因为并非所有模型都支持工具调用或 JSON 模式，此时有两种方法解决该问题：\n",
    "\n",
    "- 使用PydanticOutputParser：利用内置类来解析与给定 Pydantic 模式匹配的聊天模型的输出\n",
    "- 使用LCEL: 利用普通函数，自定义提示和解析器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: Answer the user query. Wrap the output in `json` tags\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"$defs\": {\"Person\": {\"description\": \"Information about a person.\", \"properties\": {\"name\": {\"description\": \"The name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"height_in_meters\": {\"description\": \"The height of the person expressed in meters.\", \"title\": \"Height In Meters\", \"type\": \"number\"}}, \"required\": [\"name\", \"height_in_meters\"], \"title\": \"Person\", \"type\": \"object\"}}, \"description\": \"Identifying information about all people in a text.\", \"properties\": {\"people\": {\"items\": {\"$ref\": \"#/$defs/Person\"}, \"title\": \"People\", \"type\": \"array\"}}, \"required\": [\"people\"]}\n",
      "```\n",
      "Human: 张三25岁，并且有168厘米\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(..., description=\"The name of the person\")\n",
    "    height_in_meters: float = Field(..., description=\"The height of the person expressed in meters.\")\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "    people: List[Person]\n",
    "\n",
    "# Set up a parser\n",
    "parser = PydanticOutputParser(pydantic_object=People)\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user query. Wrap the output in `json` tags\\n{format_instructions}\",\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "query = \"张三25岁，并且有168厘米\"\n",
    "print(prompt.invoke(query).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出这里prompt接受输入query，输出包含System和Human，其中System部分是按自定义结构输出生成的内容。\n",
    "\n",
    "从System部分可以看出，为People类，生成了“As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.”，要求生成的json时，最好定义为{\"foo\": [\"bar\", \"baz\"]}而不是{\"properties\": {\"foo\": [\"bar\", \"baz\"]}}。\n",
    "\n",
    "然后定义输出格式output schema，将这部分内容按json格式化后，显示如下，可以看出最外层要求输出people，而其被定义为Person的array，Person被要求输出name和height_in_meters。\n",
    "```json\n",
    "{\n",
    "    \"$defs\": {\n",
    "        \"Person\": {\n",
    "            \"description\": \"Information about a person.\",\n",
    "            \"properties\": {\n",
    "                \"name\": {\n",
    "                    \"description\": \"The name of the person\",\n",
    "                    \"title\": \"Name\",\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"height_in_meters\": {\n",
    "                    \"description\": \"The height of the person expressed in meters.\",\n",
    "                    \"title\": \"Height In Meters\",\n",
    "                    \"type\": \"number\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"name\",\n",
    "                \"height_in_meters\"\n",
    "            ],\n",
    "            \"title\": \"Person\",\n",
    "            \"type\": \"object\"\n",
    "        }\n",
    "    },\n",
    "    \"description\": \"Identifying information about all people in a text.\",\n",
    "    \"properties\": {\n",
    "        \"people\": {\n",
    "            \"items\": {\n",
    "                \"$ref\": \"#/$defs/Person\"\n",
    "            },\n",
    "            \"title\": \"People\",\n",
    "            \"type\": \"array\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\n",
    "        \"people\"\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "这里就是通过修改输入LLMs的prompt，实现结构化内容输出，langchain的作用是实现“结构化表示->prompt”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"people\": [\\n    {\\n      \"name\": \"张三\",\\n      \"height_in_meters\": 1.68\\n    }\\n  ]\\n}\\n```'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm \n",
    "\n",
    "query = \"张三25岁，并且有168厘米\"\n",
    "chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='张三', height_in_meters=1.68)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "\n",
    "query = \"张三25岁，并且有168厘米\"\n",
    "chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='张三', height_in_meters=1.68), Person(name='李四', height_in_meters=1.72)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "\n",
    "query = \"张三25岁，并且有168厘米并且李四28岁，并且有172厘米\"\n",
    "chain.invoke({\"query\": query}) # 输入包含多个实例也可以格式化输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：结构化输出，是通过修改prompt，让LLMs直接输出特定格式的内容。比如提问：“xxx，请以表格的形式显示”，而不是通过人工定义规则解析文本实现。关于如何实现“输出格式->prompt”，lanchain提供2种方式：\n",
    "\n",
    "1. 使用with_structured_output：直接为操作直接绑定自定义结构化输出，自动生成prompt\n",
    "2. 使用PydanticOutputParser：为操作自定义结构化输出，自动生成prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除此之外，还可以指定模型输出格式，并通过自定义函数解析替换以上的parser部分，实现结构化输出。综上可知，让模型输出输出结构化内容，langchain包括两个步骤：\n",
    "\n",
    "1. 使用langchain定义结构化表示，并输出修改后的prompt到LLMs，LLMs输出结构化json的字符串格式内容\n",
    "2. 解析LLMs输出为结构化内容\n",
    "\n",
    "更多高级结构化参考 https://python.langchain.ac.cn/docs/how_to/structured_output/#choosing-between-multiple-schemas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
